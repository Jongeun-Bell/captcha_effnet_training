"""
Inference Script (EfficientNet-B0)
- í•™ìŠµëœ ëª¨ë¸(best_model.pth)ë¡œ ë‹¨ì¼ ì´ë¯¸ì§€ ë˜ëŠ” ëœë¤ ì´ë¯¸ì§€ ë¶„ë¥˜
- CAPTCHA Datasetì˜ í´ë” êµ¬ì¡° ê¸°ë°˜ ìë™ ë¼ë²¨ ë§¤í•‘
"""

import os
import sys
import argparse
import random
from PIL import Image

import torch
import torch.nn as nn
from torchvision import models, transforms


# ============================================
# 0) training í´ë” import ê²½ë¡œ ì¶”ê°€
# ============================================
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))          # /ai/inference
TRAINING_DIR = os.path.abspath(os.path.join(CURRENT_DIR, "..", "training"))

sys.path.append(TRAINING_DIR)

from captcha_dataset import CAPTCHADataset  # â† ì´ì œ ì •ìƒ import ë¨


# ============================================
# 1) argparse
# ============================================
def parse_args():
    parser = argparse.ArgumentParser(description="EfficientNet Inference Script")

    parser.add_argument("--data_dir", type=str, required=True,
                        help="ì´ë¯¸ì§€ í´ë” ë£¨íŠ¸ ê²½ë¡œ (ex: ../images)")
    parser.add_argument("--model_path", type=str, required=True,
                        help="í•™ìŠµëœ best_model.pth ê²½ë¡œ")
    parser.add_argument("--image_path", type=str, default=None,
                        help="ë¶„ë¥˜í•  ì´ë¯¸ì§€ ê²½ë¡œ (ì—†ìœ¼ë©´ ëœë¤ ì„ íƒ)")

    return parser.parse_args()


# ============================================
# 2) ì´ë¯¸ì§€ ë¶„ë¥˜
# ============================================
def classify(args):
    # ì¥ì¹˜ ì„¤ì •
    device = (
        "mps" if torch.backends.mps.is_available()
        else "cuda" if torch.cuda.is_available()
        else "cpu"
    )
    print(f"ì‚¬ìš© ì¥ì¹˜: {device}")

    # ===== Dataset ë¶ˆëŸ¬ì„œ ë¼ë²¨ ë§¤í•‘ ìë™ ìƒì„± =====
    dataset = CAPTCHADataset(args.data_dir, transform=None)

    group_to_label = dataset.group_to_label
    label_to_group = {v: k for k, v in group_to_label.items()}

    NUM_CLASSES = len(label_to_group)
    print(f"ìë™ ê°ì§€ëœ í´ë˜ìŠ¤ ìˆ˜: {NUM_CLASSES}")
    print("label_to_group:", label_to_group)

    # ===== ëª¨ë¸ ìƒì„± =====
    model = models.efficientnet_b0(weights=None)
    in_features = model.classifier[1].in_features
    model.classifier[1] = nn.Linear(in_features, NUM_CLASSES)

    # ===== ëª¨ë¸ ë¡œë“œ =====
    if not os.path.exists(args.model_path):
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {args.model_path}")

    model.load_state_dict(torch.load(args.model_path, map_location=device))
    model.to(device)
    model.eval()

    # ===== ì „ì²˜ë¦¬ =====
    transform = transforms.Compose([
        transforms.Resize((128, 128)),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225],
        )
    ])

    # ============================================
    # 3) ì´ë¯¸ì§€ ì„ íƒ (ëœë¤ or ì§€ì •)
    # ============================================
    if args.image_path is None:
        print("\nğŸ“Œ image_pathê°€ ì—†ì–´ì„œ ëœë¤ ì´ë¯¸ì§€ ì„ íƒí•©ë‹ˆë‹¤.")

        all_images = []

        # 2ë‹¨ê³„ í´ë”(images/group/class) ìˆœíšŒí•˜ë©° ì´ë¯¸ì§€ ìˆ˜ì§‘
        for group in os.listdir(args.data_dir):
            group_path = os.path.join(args.data_dir, group)
            if not os.path.isdir(group_path):
                continue

            for cls in os.listdir(group_path):
                cls_path = os.path.join(group_path, cls)
                if not os.path.isdir(cls_path):
                    continue

                for f in os.listdir(cls_path):
                    if f.lower().endswith(('.jpg', '.jpeg', '.png')):
                        all_images.append(os.path.join(cls_path, f))

        if len(all_images) == 0:
            raise RuntimeError("data_dir ì•ˆì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

        img_path = random.choice(all_images)
        print(f"ğŸ¯ ì„ íƒëœ ëœë¤ ì´ë¯¸ì§€: {img_path}")

    else:
        img_path = args.image_path
        if not os.path.exists(img_path):
            raise FileNotFoundError(f"ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {img_path}")

        print(f"\nğŸ¯ ì§€ì •ëœ ì´ë¯¸ì§€: {img_path}")

    # ============================================
    # 4) ì¶”ë¡ 
    # ============================================
    img = Image.open(img_path).convert("RGB")
    x = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(x)
        probs = torch.softmax(outputs, dim=1)[0].cpu().numpy()
        pred_idx = probs.argmax()

    predicted_group = label_to_group[pred_idx]
    confidence = probs[pred_idx]

    # ============================================
    # 5) ì¶œë ¥
    # ============================================
    print("\n===== ì˜ˆì¸¡ ê²°ê³¼ =====")
    print(f"ì˜ˆì¸¡ í´ë˜ìŠ¤: {predicted_group}")
    print(f"ì‹ ë¢°ë„: {confidence*100:.2f}%")
    print("\ní™•ë¥  ë¶„í¬:")
    for i in range(NUM_CLASSES):
        print(f"  {label_to_group[i]} : {probs[i]*100:.2f}%")

    return {
        "predicted_label": predicted_group,
        "confidence": float(confidence),
        "probabilities": {label_to_group[i]: float(probs[i]) for i in range(NUM_CLASSES)}
    }


# ============================================
# ì‹¤í–‰
# ============================================
if __name__ == "__main__":
    args = parse_args()
    classify(args)

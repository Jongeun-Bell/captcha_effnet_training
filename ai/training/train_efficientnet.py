"""
EfficientNet-B0 í•™ìŠµ ì½”ë“œ (CAPTCHA ë°ì´í„°ìš©)
- 2ë‹¨ê³„ í´ë”(images/group/classname) êµ¬ì¡° ìë™ ì§€ì›
- í´ë˜ìŠ¤ ê°œìˆ˜(NUM_CLASSES) ìë™ ê³„ì‚°
- MLflow ì—°ë™ (file:./mlruns ê³ ì •) - ì¶”í›„ ì„œë²„ ip ì£¼ì†Œë¡œ ë³€ê²½ í•„ìˆ˜
- argparseëŠ” main() ë‚´ë¶€ì—ì„œë§Œ ì‹¤í–‰ë˜ë„ë¡ í™í† ë§
"""

import os
import time
import argparse
from datetime import datetime

import torch
from torch import nn, optim
from torchvision import transforms, models
from torch.utils.data import DataLoader, random_split

import mlflow
import mlflow.pytorch
from mlflow.models.signature import infer_signature

from captcha_dataset import CAPTCHADataset


# ============================================================
# í•™ìŠµ í•¨ìˆ˜
# ============================================================
def main():
    # ------------------------
    # argparse ì„¤ì •
    # ------------------------
    parser = argparse.ArgumentParser(description="EfficientNet CAPTCHA Training Script")

    parser.add_argument("--data_dir", type=str, required=True,
                        help="í•™ìŠµ ë°ì´í„°(images) ê²½ë¡œ (ì˜ˆ: ./images)")
    parser.add_argument("--output_dir", type=str, default="./models",
                        help="ëª¨ë¸ ì €ì¥ í´ë”")
    parser.add_argument("--batch_size", type=int, default=64)
    parser.add_argument("--learning_rate", type=float, default=0.0003)
    parser.add_argument("--epochs", type=int, default=20)
    parser.add_argument("--patience", type=int, default=3)

    args = parser.parse_args()

    data_dir = args.data_dir
    output_dir = args.output_dir
    batch_size = args.batch_size
    learning_rate = args.learning_rate
    num_epochs = args.epochs
    patience = args.patience

    # ------------------------
    # ì¶œë ¥ í´ë” ìƒì„±
    # ------------------------
    os.makedirs(output_dir, exist_ok=True)
    model_save_path = os.path.join(output_dir, "best_model.pth")

    # ------------------------
    # MLflow ì„¤ì •
    # ------------------------
    mlflow.set_tracking_uri("file:./mlruns")
    mlflow.set_experiment("captcha-effnet-v2")

    run_name = f"effnet_lr{learning_rate}_bs{batch_size}_{datetime.now().strftime('%Y%m%d_%H%M')}"

    # ------------------------
    # ì „ì²˜ë¦¬ ì •ì˜
    # ------------------------
    train_transform = transforms.Compose([
        transforms.Resize((128, 128)),
        transforms.RandomRotation(15),
        transforms.ColorJitter(brightness=0.2, contrast=0.2),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ])

    val_transform = transforms.Compose([
        transforms.Resize((128, 128)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ])

    # ============================================================
    # ë°ì´í„° ë¡œë“œ
    # ============================================================
    print("=" * 60)
    print("ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
    print("=" * 60)

    full_dataset = CAPTCHADataset(data_dir, transform=None)

    # train/val ë¶„ë¦¬
    train_ratio = 0.8
    val_ratio = 0.2

    total_size = len(full_dataset)
    train_size = int(total_size * train_ratio)
    val_size = total_size - train_size

    train_subset, val_subset = random_split(full_dataset, [train_size, val_size])

    train_subset.dataset.transform = train_transform
    val_subset.dataset.transform = val_transform

    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)

    print(f"ì´ ë°ì´í„°: {total_size}ê°œ")
    print(f"í•™ìŠµ ë°ì´í„°: {train_size}ê°œ")
    print(f"ê²€ì¦ ë°ì´í„°: {val_size}ê°œ\n")

    # ============================================================
    # ëª¨ë¸ ì„¤ì •
    # ============================================================
    print("=" * 60)
    print("ëª¨ë¸ ì„¤ì • ì¤‘...")
    print("=" * 60)

    device = "mps" if torch.backends.mps.is_available() else \
             "cuda" if torch.cuda.is_available() else "cpu"

    print(f"ì‚¬ìš© ì¥ì¹˜: {device}\n")

    model = models.efficientnet_b0(weights="IMAGENET1K_V1")

    # ------------------------
    # í´ë˜ìŠ¤ ê°œìˆ˜ ìë™ ê³„ì‚°
    # ------------------------
    NUM_CLASSES = len(set(full_dataset.labels))
    print(f"ê°ì§€ëœ ì‹¤ì œ í´ë˜ìŠ¤ ìˆ˜: {NUM_CLASSES}")

    in_features = model.classifier[1].in_features
    model.classifier[1] = nn.Linear(in_features, NUM_CLASSES)

    model.to(device)

    print(f"âœ… EfficientNet-B0 ë¡œë“œ ì™„ë£Œ ({NUM_CLASSES}ê°œ í´ë˜ìŠ¤)\n")

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)

    # ============================================================
    # MLflow ê¸°ë¡ + í•™ìŠµ ì‹œì‘
    # ============================================================
    print("=" * 60)
    print("í•™ìŠµ ì‹œì‘")
    print("=" * 60 + "\n")

    start_total = time.time()
    best_accuracy = 0
    patience_counter = 0

    # signature ìƒì„±ìš© ì…ë ¥ ì˜ˆì‹œ
    example_input = torch.randn(1, 3, 128, 128).to(device)
    with torch.no_grad():
        example_output = model(example_input)

    signature = infer_signature(
        example_input.cpu().numpy(),
        example_output.cpu().numpy()
    )

    # ----------------------------
    # MLflow RUN
    # ----------------------------
    with mlflow.start_run(run_name=run_name):

        mlflow.log_param("run_name", run_name)
        mlflow.log_param("batch_size", batch_size)
        mlflow.log_param("learning_rate", learning_rate)
        mlflow.log_param("num_epochs", num_epochs)
        mlflow.log_param("patience", patience)
        mlflow.log_param("train_samples", train_size)
        mlflow.log_param("val_samples", val_size)
        mlflow.log_param("num_classes", NUM_CLASSES)

        # ============================================================
        # EPOCH LOOP
        # ============================================================
        for epoch in range(num_epochs):
            epoch_start = time.time()

            # ------------------------
            # Train
            # ------------------------
            model.train()
            train_loss = 0.0
            train_correct = 0
            train_total = 0

            for batch_idx, (imgs, labels) in enumerate(train_loader):
                imgs, labels = imgs.to(device), labels.to(device)

                optimizer.zero_grad()
                outputs = model(imgs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                train_loss += loss.item()
                _, predicted = torch.max(outputs, 1)
                train_total += labels.size(0)
                train_correct += (predicted == labels).sum().item()

                if (batch_idx + 1) % 10 == 0:
                    print(f"  [{batch_idx+1}/{len(train_loader)}] Loss: {loss.item():.4f}")

            avg_train_loss = train_loss / len(train_loader)
            train_accuracy = train_correct / train_total

            # ------------------------
            # Validation
            # ------------------------
            model.eval()
            val_loss = 0.0
            val_correct = 0
            val_total = 0

            with torch.no_grad():
                for imgs, labels in val_loader:
                    imgs, labels = imgs.to(device), labels.to(device)

                    outputs = model(imgs)
                    loss = criterion(outputs, labels)

                    val_loss += loss.item()
                    _, predicted = torch.max(outputs, 1)
                    val_total += labels.size(0)
                    val_correct += (predicted == labels).sum().item()

            avg_val_loss = val_loss / len(val_loader)
            val_accuracy = val_correct / val_total

            scheduler.step()
            epoch_time = time.time() - epoch_start

            # ------------------------
            # Epoch ê²°ê³¼ ì¶œë ¥
            # ------------------------
            print(f"[Epoch {epoch+1}/{num_epochs}]")
            print(f"  Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.2%}")
            print(f"  Val Loss:   {avg_val_loss:.4f} | Val Acc:   {val_accuracy:.2%}")
            print(f"  â†’ Epoch Time: {epoch_time:.2f} sec")

            gap = train_accuracy - val_accuracy
            if gap >= 0.10:
                print(f"  âš ï¸ ê³¼ì í•© ê²½ê³ ! (ì°¨ì´: {gap:.2%})")
            else:
                print(f"  âœ“ ì •ìƒ (ì°¨ì´: {gap:.2%})")

            # mlflow ê¸°ë¡
            mlflow.log_metric("train_loss", avg_train_loss, step=epoch)
            mlflow.log_metric("train_acc", train_accuracy, step=epoch)
            mlflow.log_metric("val_loss", avg_val_loss, step=epoch)
            mlflow.log_metric("val_acc", val_accuracy, step=epoch)
            mlflow.log_metric("learning_rate", optimizer.param_groups[0]['lr'], step=epoch)

            # ------------------------
            # Early Stopping
            # ------------------------
            if val_accuracy > best_accuracy:
                best_accuracy = val_accuracy
                patience_counter = 0

                torch.save(model.state_dict(), model_save_path)
                print(f"  âœ… ìµœê³  ëª¨ë¸ ì €ì¥! (Val_Acc: {val_accuracy:.2%})")

                mlflow.pytorch.log_model(
                    model,
                    name="best_model",
                    signature=signature
                )
            else:
                patience_counter += 1
                print(f"  â³ Patience: {patience_counter}/{patience}")

                if patience_counter >= patience:
                    print("\nğŸ›‘ Early Stopping ë°œë™!")
                    print(f"ìµœê³  ê²€ì¦ ì •í™•ë„: {best_accuracy:.2%}")
                    break

            print()

        # best accuracy ê¸°ë¡
        mlflow.log_metric("best_val_acc", best_accuracy)

    # ============================================================
    # ì™„ë£Œ ì¶œë ¥
    # ============================================================
    end_total = time.time()
    print("=" * 60)
    print("í•™ìŠµ ì™„ë£Œ!")
    print(f"ìµœê³  ê²€ì¦ ì •í™•ë„: {best_accuracy:.2%}")
    print(f"ì „ì²´ í•™ìŠµ ì‹œê°„: {end_total - start_total:.2f} sec")
    print(f"ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {model_save_path}")
    print("=" * 60)


# ============================================================
# ì‹¤í–‰
# ============================================================
if __name__ == "__main__":
    main()

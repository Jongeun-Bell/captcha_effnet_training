import torch
from torch import nn, optim
from torchvision import transforms, models
from torch.utils.data import DataLoader, random_split
import time

# CAPTCHADataset ì„í¬íŠ¸ (ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•¨)
from captcha_dataset import CAPTCHADataset

# ============================================
# ë°ì´í„° ë¡œë“œ
# ============================================
data_dir = "/Users/bell/Desktop/PYTHON/captcha/images/"

# ì „ì²˜ë¦¬ ì •ì˜ (í•™ìŠµìš© - ì¦ê°• í¬í•¨)
train_transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.RandomRotation(15),  # ë°ì´í„° ì¦ê°•
    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # ë°ì´í„° ì¦ê°•
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

# ì „ì²˜ë¦¬ ì •ì˜ (ê²€ì¦ìš© - ì¦ê°• ì—†ìŒ)
val_transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

# CAPTCHADatasetìœ¼ë¡œ ë°ì´í„°ì…‹ ë¡œë“œ (ë™ë¬¼/ì‚¬ë¬¼ë¡œ ê·¸ë£¹í•‘ë¨)
print("CAPTCHADataset ë¡œë“œ ì¤‘...")
full_dataset = CAPTCHADataset(data_dir, transform=train_transform)

# í•™ìŠµ/ê²€ì¦ ë¶„í• 
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_ds, val_ds = random_split(full_dataset, [train_size, val_size])

# DataLoader ìƒì„±
train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)
val_loader = DataLoader(val_ds, batch_size=64, shuffle=False)

print(f"ì´ ë°ì´í„°: {len(full_dataset)}ê°œ")
print(f"í•™ìŠµ ë°ì´í„°: {len(train_ds)}ê°œ")
print(f"ê²€ì¦ ë°ì´í„°: {len(val_ds)}ê°œ")
print(f"í´ë˜ìŠ¤: Animal(0), Object(1) - 2ê°œ ê·¸ë£¹\n")

# ============================================
# ëª¨ë¸ ì„¤ì •
# ============================================
device = "mps" if torch.backends.mps.is_available() else "cpu"
print(f"ì‚¬ìš© ì¥ì¹˜: {device}\n")

# EfficientNet-B0 ë¡œë“œ (ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜)
model = models.efficientnet_b0(weights="IMAGENET1K_V1")

# ë¶„ë¥˜ì¸µ ìˆ˜ì • (2ê°œ í´ë˜ìŠ¤: ë™ë¬¼, ì‚¬ë¬¼)
in_features = model.classifier[1].in_features
model.classifier[1] = nn.Linear(in_features, 2)

model.to(device)

# ============================================
# ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €, ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
# ============================================
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.classifier.parameters(), lr=0.0001)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)

# ============================================
# í•™ìŠµ ë£¨í”„
# ============================================
print("=" * 60)
print("í•™ìŠµ ì‹œì‘")
print("=" * 60 + "\n")

start_total = time.time()

best_accuracy = 0
patience_counter = 0
patience = 3

for epoch in range(10):
    epoch_start = time.time()
    
    # ========== í•™ìŠµ ë‹¨ê³„ ==========
    model.train()
    train_loss = 0
    train_correct = 0
    train_total = 0
    
    for batch_idx, (imgs, labels) in enumerate(train_loader):
        # ì¥ì¹˜ë¡œ ì´ë™
        imgs, labels = imgs.to(device), labels.to(device)
        
        # ê¸°ìš¸ê¸° ì´ˆê¸°í™”
        optimizer.zero_grad()
        
        # ìˆœì „íŒŒ
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        
        # ì—­ì „íŒŒ
        loss.backward()
        optimizer.step()
        
        # ì†ì‹¤ ëˆ„ì 
        train_loss += loss.item()
        
        # ì •í™•ë„ ê³„ì‚°
        _, predicted = torch.max(outputs.data, 1)
        train_total += labels.size(0)
        train_correct += (predicted == labels).sum().item()
    
    # í•™ìŠµ ì—í¬í¬ í‰ê· 
    avg_train_loss = train_loss / len(train_loader)
    train_accuracy = train_correct / train_total
    
    epoch_end = time.time()
    
    # ========== ê²€ì¦ ë‹¨ê³„ ==========
    model.eval()
    val_correct = 0
    val_total = 0
    
    with torch.no_grad():
        for imgs, labels in val_loader:
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = model(imgs)
            _, predicted = torch.max(outputs.data, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()
    
    val_accuracy = val_correct / val_total
    
    # í•™ìŠµë¥  ê°ì†Œ
    scheduler.step()
    
    # ========== ê²°ê³¼ ì¶œë ¥ ==========
    print(f"[Epoch {epoch+1}/10] Train Loss: {avg_train_loss:.4f}")
    print(f"  Train Acc: {train_accuracy:.2%} | Val Acc: {val_accuracy:.2%}")
    print(f"  â†’ Epoch Time: {epoch_end - epoch_start:.2f} sec")
    
    # ========== ê³¼ì í•© íŒë‹¨ ==========
    overfitting_gap = train_accuracy - val_accuracy
    if overfitting_gap >= 0.10:
        print(f"  âš ï¸ ê³¼ì í•© ê²½ê³ ! (Train-Val ì°¨ì´: {overfitting_gap:.2%})")
    
    # ========== ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥ ==========
    if val_accuracy > best_accuracy and overfitting_gap < 0.10:
        best_accuracy = val_accuracy
        patience_counter = 0
        torch.save(model.state_dict(), 'best_model.pth')
        print(f"  âœ… ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥! (Val_Acc: {val_accuracy:.2%})")
    else:
        patience_counter += 1
        if patience_counter >= patience:
            print(f"\nğŸ›‘ Early Stopping! ìµœê³  ê²€ì¦ ì •í™•ë„: {best_accuracy:.2%}")
            break
    
    print()

# ============================================
# ì „ì²´ í•™ìŠµ ì‹œê°„ ì¶œë ¥
# ============================================
end_total = time.time()
total_time = end_total - start_total

print("=" * 60)
print(f"í•™ìŠµ ì™„ë£Œ!")
print(f"ìµœê³  ê²€ì¦ ì •í™•ë„: {best_accuracy:.2%}")
print(f"ì „ì²´ í•™ìŠµ ì‹œê°„: {total_time:.2f} sec ({total_time/60:.2f} min)")
print("=" * 60)

# ============================================
# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ ë° ìµœì¢… ê²€ì¦
# ============================================
print("\nìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ ì¤‘...")
model.load_state_dict(torch.load('best_model.pth'))
model.eval()

final_correct = 0
final_total = 0

with torch.no_grad():
    for imgs, labels in val_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        outputs = model(imgs)
        _, predicted = torch.max(outputs.data, 1)
        final_total += labels.size(0)
        final_correct += (predicted == labels).sum().item()

final_accuracy = final_correct / final_total
print(f"ìµœì¢… ê²€ì¦ ì •í™•ë„: {final_accuracy:.2%}")
print(f"âœ… ëª¨ë¸ ì €ì¥ë¨: best_model.pth")